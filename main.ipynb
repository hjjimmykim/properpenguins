{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 0\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 0\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 100           # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab+1, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, test, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1) # Same encoder as item context\n",
    "        \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h1,c1) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h2,c2) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h3,c3) = self.lstm2(x3[i].view(1,self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],2).view(self.batch_size,-1)\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) - ((one_tensor-p_term) * (one_tensor-p_term+1e-8).log())\n",
    "        \n",
    "        if test:\n",
    "            # Greedy\n",
    "            term = torch.round(p_term).long()\n",
    "        else:\n",
    "            # Sample\n",
    "            term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                letter = p_letter.argmax(dim=1).view(self.batch_size,1).long()\n",
    "            else:\n",
    "                # Sample\n",
    "                letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)     \n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.sigmoid(self.policy_prop[i](h)))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                #prop[:,i] = p_prop[i].argmax(dim=1)\n",
    "                prop.append(p_prop[i].argmax(dim=1))\n",
    "            else:\n",
    "                # Sample\n",
    "                #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "                prop.append(torch.multinomial(p_prop,1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        #print(entropy_loss.size())\n",
    "        entropy_loss = entropy_loss.mean()\n",
    "        #print(entropy_loss)\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z],True)\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-10: 1.04689359664917s\n",
      "Runtime for episodes 10-20: 0.9557099342346191s\n",
      "Runtime for episodes 20-30: 1.5979328155517578s\n",
      "Runtime for episodes 30-40: 0.7955899238586426s\n",
      "Runtime for episodes 40-50: 0.8343038558959961s\n",
      "Runtime for episodes 50-60: 1.1012766361236572s\n",
      "Runtime for episodes 60-70: 0.729727029800415s\n",
      "Runtime for episodes 70-80: 1.0104353427886963s\n",
      "Runtime for episodes 80-90: 0.6696772575378418s\n",
      "End ------------------\n",
      "Total runtime: 9.335510730743408s\n"
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], True, num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "            \n",
    "        # Accumulate entropy loss\n",
    "        losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "        losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(losses[i])\n",
    "        #print(Agents[i].ff_ling.weight.grad)\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEJGESxCCCFkFMEihBBCRhEsQgghZPQ/id9CyeoKhZ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae4c092550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_mean.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
