{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 1\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 0\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 5000           # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab+1, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, test, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1) # Same encoder as item context\n",
    "        \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h1,c1) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h2,c2) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h3,c3) = self.lstm2(x3[i].view(1,self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],2).view(self.batch_size,-1)\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) - ((one_tensor-p_term) * (one_tensor-p_term+1e-8).log())\n",
    "        \n",
    "        if test:\n",
    "            # Greedy\n",
    "            term = torch.round(p_term).long()\n",
    "        else:\n",
    "            # Sample\n",
    "            term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                letter = p_letter.argmax(dim=1).view(self.batch_size,1).long()\n",
    "            else:\n",
    "                # Sample\n",
    "                letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)     \n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.sigmoid(self.policy_prop[i](h)))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                #prop[:,i] = p_prop[i].argmax(dim=1)\n",
    "                prop.append(p_prop[i].argmax(dim=1))\n",
    "            else:\n",
    "                # Sample\n",
    "                #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "                prop.append(torch.multinomial(p_prop,1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        #print(entropy_loss.size())\n",
    "        entropy_loss = entropy_loss.sum()\n",
    "        #print(entropy_loss)\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z],True)\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-500: 52.1859016418457s\n",
      "Runtime for episodes 500-1000: 43.15954875946045s\n",
      "Runtime for episodes 1000-1500: 41.56451368331909s\n",
      "Runtime for episodes 1500-2000: 38.92331290245056s\n",
      "Runtime for episodes 2000-2500: 37.137011766433716s\n",
      "Runtime for episodes 2500-3000: 37.09312415122986s\n",
      "Runtime for episodes 3000-3500: 37.77393293380737s\n",
      "Runtime for episodes 3500-4000: 40.36529016494751s\n",
      "Runtime for episodes 4000-4500: 41.87433576583862s\n",
      "End ------------------\n",
      "Total runtime: 405.8406422138214s\n"
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], True, num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "            \n",
    "        # Accumulate entropy loss\n",
    "        losses[id_1] += entropy_losses[id_1]\n",
    "        losses[id_2] += entropy_losses[id_2]\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(losses[i])\n",
    "        #print(Agents[i].ff_ling.weight.grad)\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOMzMrBAnDjMzK8SJw8zMCvk/CH6f33GREf8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb122b3ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
