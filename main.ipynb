{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 1\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 0\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 1000            # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab+1, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, test, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1) # Same encoder as item context\n",
    "        \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h1,c1) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h2,c2) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h3,c3) = self.lstm2(x3[i].view(1,self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],2).squeeze()\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term_tensor = -(p_term * (p_term+1e-8).log()) - ((one_tensor-p_term) * (one_tensor-p_term+1e-8).log())\n",
    "        entropy_term = torch.sum(entropy_term_tensor)\n",
    "        #print(entropy_term)\n",
    "        \n",
    "        if test:\n",
    "            # Greedy\n",
    "            term = torch.round(p_term).long()\n",
    "        else:\n",
    "            # Sample\n",
    "            term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                letter = p_letter.argmax(dim=1).view(self.batch_size,1).long()\n",
    "            else:\n",
    "                # Sample\n",
    "                letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter)     \n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.sigmoid(self.policy_prop[i](h)))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log())\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                #prop[:,i] = p_prop[i].argmax(dim=1)\n",
    "                prop.append(p_prop[i].argmax(dim=1))\n",
    "            else:\n",
    "                # Sample\n",
    "                #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "                prop.append(torch.multinomial(p_prop,1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = sum(entropy_prop_list) # Entropy for exploration\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = torch.sum(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "\n",
    "        return (term,message,prop, entropy_loss, log_p_term,log_p_letter,log_p_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z],True)\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-100: 20.237462520599365s\n",
      "Runtime for episodes 100-200: 12.37045669555664s\n",
      "Runtime for episodes 200-300: 10.010237455368042s\n",
      "Runtime for episodes 300-400: 9.920172691345215s\n",
      "Runtime for episodes 400-500: 9.880614519119263s\n",
      "Runtime for episodes 500-600: 9.172619342803955s\n",
      "Runtime for episodes 600-700: 8.46423625946045s\n",
      "Runtime for episodes 700-800: 9.577234983444214s\n",
      "Runtime for episodes 800-900: 11.629486083984375s\n",
      "End ------------------\n",
      "Total runtime: 112.26849174499512s\n"
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss, lt,ll,lp = Agent([item_context, prev_messages, prev_proposals], True, num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "            \n",
    "        # Accumulate entropy loss\n",
    "        losses[id_1] -= entropy_losses[id_1]\n",
    "        losses[id_2] -= entropy_losses[id_2]\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(Agents[i].ff_ling.weight.grad)\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9g4YuwbnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1916073128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "#plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
