{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 1\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 0\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 100           # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab+1, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, test, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1) # Same encoder as item context\n",
    "        \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h1,c1) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h2,c2) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h3,c3) = self.lstm2(x3[i].view(1,self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],2).view(self.batch_size,-1)\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) - ((one_tensor-p_term) * (one_tensor-p_term+1e-8).log())\n",
    "        \n",
    "        if test:\n",
    "            # Greedy\n",
    "            term = torch.round(p_term).long()\n",
    "        else:\n",
    "            # Sample\n",
    "            term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                letter = p_letter.argmax(dim=1).view(self.batch_size,1).long()\n",
    "            else:\n",
    "                # Sample\n",
    "                letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)     \n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.sigmoid(self.policy_prop[i](h)))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                #prop[:,i] = p_prop[i].argmax(dim=1)\n",
    "                prop.append(p_prop[i].argmax(dim=1))\n",
    "            else:\n",
    "                # Sample\n",
    "                #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "                prop.append(torch.multinomial(p_prop,1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        #print(entropy_loss.size())\n",
    "        entropy_loss = entropy_loss.mean()\n",
    "        #print(entropy_loss)\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z],True)\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-10: 1.0524325370788574s\n",
      "Runtime for episodes 10-20: 0.579373836517334s\n",
      "Runtime for episodes 20-30: 1.1179816722869873s\n",
      "Runtime for episodes 30-40: 0.5573034286499023s\n",
      "Runtime for episodes 40-50: 1.2603936195373535s\n",
      "Runtime for episodes 50-60: 0.6068048477172852s\n",
      "Runtime for episodes 60-70: 1.163102388381958s\n",
      "Runtime for episodes 70-80: 1.5010015964508057s\n",
      "Runtime for episodes 80-90: 0.5282399654388428s\n",
      "End ------------------\n",
      "Total runtime: 8.851698637008667s\n"
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], True, num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "            \n",
    "        # Accumulate entropy loss\n",
    "        losses[id_1] += entropy_losses[id_1]\n",
    "        losses[id_2] += entropy_losses[id_2]\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(losses[i])\n",
    "        #print(Agents[i].ff_ling.weight.grad)\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04f01e3b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_mean.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
