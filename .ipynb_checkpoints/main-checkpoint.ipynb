{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 1\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 0\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 100000           # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab+1, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, test, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1) # Same encoder as item context\n",
    "        \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h1,c1) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h2,c2) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h3,c3) = self.lstm2(x3[i].view(1,self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],2).view(self.batch_size,-1)\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) - ((one_tensor-p_term) * (one_tensor-p_term+1e-8).log())\n",
    "        \n",
    "        if test:\n",
    "            # Greedy\n",
    "            term = torch.round(p_term).long()\n",
    "        else:\n",
    "            # Sample\n",
    "            term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                letter = p_letter.argmax(dim=1).view(self.batch_size,1).long()\n",
    "            else:\n",
    "                # Sample\n",
    "                letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)     \n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.sigmoid(self.policy_prop[i](h)))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                #prop[:,i] = p_prop[i].argmax(dim=1)\n",
    "                prop.append(p_prop[i].argmax(dim=1))\n",
    "            else:\n",
    "                # Sample\n",
    "                #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "                prop.append(torch.multinomial(p_prop,1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        #print(entropy_loss.size())\n",
    "        entropy_loss = entropy_loss.sum()\n",
    "        #print(entropy_loss)\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z],True)\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-1000: 106.37494230270386s\n",
      "Runtime for episodes 1000-2000: 96.3989691734314s\n",
      "Runtime for episodes 2000-3000: 89.66538381576538s\n",
      "Runtime for episodes 3000-4000: 83.15606617927551s\n",
      "Runtime for episodes 4000-5000: 105.79041242599487s\n",
      "Runtime for episodes 5000-6000: 117.4050989151001s\n",
      "Runtime for episodes 6000-7000: 118.59624314308167s\n",
      "Runtime for episodes 7000-8000: 123.45249557495117s\n",
      "Runtime for episodes 8000-9000: 129.26563024520874s\n",
      "End ------------------\n",
      "Total runtime: 1111.6336703300476s\n"
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], True, num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "            \n",
    "        # Accumulate entropy loss\n",
    "        losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "        losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(losses[i])\n",
    "        #print(Agents[i].ff_ling.weight.grad)\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwfvDftoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9e4a38908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_sum_refreg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
