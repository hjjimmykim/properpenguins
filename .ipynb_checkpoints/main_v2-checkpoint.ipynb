{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "v2: embedding layers & encoding LSTM change <br>\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 1\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 3\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool (item num = 0-max_item)\n",
    "max_utility = 10       # Maximum utility value for agents (utility = 0-max_utility)\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 1000           # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = False\n",
    "xavier_init = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        self.encoder_pool_prop = nn.Embedding(max_item+1,embedding_dim)\n",
    "        self.encoder_utility = nn.Embedding(max_utility+1,embedding_dim)\n",
    "        self.encoder_ling = nn.Embedding(num_vocab,embedding_dim)\n",
    "\n",
    "        # Feedforwards\n",
    "        self.ff_pool = nn.Linear(num_types*embedding_dim,embedding_dim)\n",
    "        self.ff_utility = nn.Linear(num_types*embedding_dim,embedding_dim)\n",
    "        self.ff_prop = nn.Linear(num_types*embedding_dim,embedding_dim)\n",
    "\n",
    "        # Linguistic LSTM\n",
    "        self.lstm_ling = nn.LSTMCell(embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(4*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Init\n",
    "        if xavier_init:\n",
    "            torch.nn.init.xavier_uniform_(self.encoder_pool_prop.weight,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.encoder_utility.weight,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.encoder_ling.weight,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.ff_pool.weight,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.ff_utility.weight,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.ff_prop.weight,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.lstm_ling.weight_ih,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.lstm_ling.weight_hh,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.ff.weight,gain=1)\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTMCell(embedding_dim, embedding_dim)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "        if xavier_init:\n",
    "            torch.nn.init.xavier_uniform_(self.policy_term.weight,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.policy_ling.weight_ih,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.policy_ling.weight_hh,gain=1)\n",
    "            torch.nn.init.xavier_uniform_(self.ff_ling.weight,gain=1)\n",
    "            for i in range(num_types):\n",
    "                torch.nn.init.xavier_uniform_(self.policy_prop[i].weight,gain=1)\n",
    "        \n",
    "    def forward(self, x, test, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        x1_pool = x1[:,:num_types]\n",
    "        x1_util = x1[:,num_types:]\n",
    "        \n",
    "        # Initial embedding\n",
    "        x1_pool = self.encoder_pool_prop(x1_pool).view(self.batch_size,num_types*self.embedding_dim)\n",
    "        x1_util = self.encoder_utility(x1_util).view(self.batch_size,num_types*self.embedding_dim)\n",
    "\n",
    "        x2 = self.encoder_ling(x2).transpose(0,1)\n",
    "        x3 = self.encoder_pool_prop(x3).view(self.batch_size,num_types*self.embedding_dim)\n",
    "        \n",
    "        # FF for pool\n",
    "        x1_pool = self.ff_pool(x1_pool)\n",
    "        x1_p_encoded = F.relu(x1_pool)\n",
    "        \n",
    "        # FF for utility\n",
    "        x1_util = self.ff_utility(x1_util)\n",
    "        x1_u_encoded = F.relu(x1_util)\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        #h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        #c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            (h2,c2) = self.lstm_ling(x2[i].view(self.batch_size,self.embedding_dim),(h2,c2))\n",
    "            #_,(h2,c2) = self.lstm_ling(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2.view(self.batch_size,self.embedding_dim)\n",
    "        \n",
    "        # FF for proposal\n",
    "        x3 = self.ff_prop(x3)\n",
    "        x3_encoded = F.relu(x3)\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_p_encoded,x1_u_encoded,x2_encoded,x3_encoded],1).view(self.batch_size,4*self.embedding_dim)\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) - ((one_tensor-p_term) * (one_tensor-p_term+1e-8).log())\n",
    "        \n",
    "        if test:\n",
    "            # Greedy\n",
    "            term = torch.round(p_term).long()\n",
    "        else:\n",
    "            # Sample\n",
    "            term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        #h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        #c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder_ling(letter)\n",
    "\n",
    "            (h_ling,c_ling) = self.policy_ling(embedded_letter.view(self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            #_,(h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                letter = p_letter.argmax(dim=1).view(self.batch_size,1).long()\n",
    "            else:\n",
    "                # Sample\n",
    "                letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)     \n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.sigmoid(self.policy_prop[i](h)))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                #prop[:,i] = p_prop[i].argmax(dim=1)\n",
    "                prop.append(p_prop[i].argmax(dim=1))\n",
    "            else:\n",
    "                # Sample\n",
    "                #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "                prop.append(torch.multinomial(p_prop[i],1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        # Over batches ------------------------------------------------------------------------------------\n",
    "        entropy_loss = entropy_loss.sum()\n",
    "        #print(entropy_loss)\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z],True)\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-100: 11.616596221923828s\n",
      "Runtime for episodes 100-200: 13.782497644424438s\n",
      "Runtime for episodes 200-300: 10.933245658874512s\n",
      "Runtime for episodes 300-400: 10.943456172943115s\n",
      "Runtime for episodes 400-500: 10.942048072814941s\n",
      "Runtime for episodes 500-600: 10.843095064163208s\n",
      "Runtime for episodes 600-700: 10.823619604110718s\n",
      "Runtime for episodes 700-800: 10.867516279220581s\n",
      "Runtime for episodes 800-900: 10.898986339569092s\n",
      "End ------------------\n",
      "Total runtime: 112.4534547328949s\n"
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], False, num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "            \n",
    "        # Accumulate entropy loss\n",
    "        losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "        losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(losses[i])\n",
    "        #print(Agents[i].ff_ling.weight.grad)\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85b170f208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('cell_v2_N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_sum_paperreg_xavier.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
