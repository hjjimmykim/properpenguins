{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2   # Number of agents playing the game\n",
    "num_types = 3    # Number of item types\n",
    "max_item = 5     # Maximum number of each item in a pool\n",
    "max_utility = 10 # Maximum utility value for agents\n",
    "num_games = 128  # Number of games per episode\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7     # Poisson parameter\n",
    "max_N = 10  # Maximum number of turns\n",
    "min_N = 4   # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10   # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6  # Linguistic message length\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05  # Entropy regularizer for pi_term, pi_prop\n",
    "lambda2 = 0.001 # Entropy regularizer for pi_utt\n",
    "smoothing_const = 0.7 # Smoothing constant for the exponential moving average baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample an item pool for a game\n",
    "def create_item_pool(num_types, max_item, batch_size):\n",
    "    # Possible to have zero items?\n",
    "    pool = np.random.randint(0, max_item+1, (batch_size,num_types))\n",
    "    return torch.from_numpy(pool).long()\n",
    "        \n",
    "# Sample agent utility\n",
    "def create_agent_utility(num_types, max_utility, batch_size):\n",
    "    utility = np.zeros((batch_size,num_types)) # Initialize zero vector\n",
    "    \n",
    "    while 0 in np.sum(utility,1): # At least one item has to have non-zero utility\n",
    "        utility = np.random.randint(0, max_utility+1, [batch_size, num_types])\n",
    "\n",
    "    return torch.from_numpy(utility).long()\n",
    "\n",
    "# Calculate reward\n",
    "def reward(share, utility):\n",
    "    return np.dot(utility, share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = []\n",
    "        for i in range(num_types):\n",
    "            ff = nn.Linear(embedding_dim, max_item)\n",
    "            self.policy_prop.append(ff)\n",
    "        \n",
    "    def forward(self, x, test):\n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "        \n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1)\n",
    "            \n",
    "        # LSTM for item context\n",
    "        h = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h,c) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h,c))\n",
    "        x1 = h\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h,c) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h,c))\n",
    "        x2 = h\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h,c) = self.lstm2(x3[i].view(1,self.batch_size,self.embedding_dim),(h,c))\n",
    "        x3 = h\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        x = torch.cat([x1,x2,x3],2)\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(x)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).view(self.batch_size,1)\n",
    "        \n",
    "        entropy_term = -(p_term * p_term.log2()) - (torch.ones(128,1)-p_term * (torch.ones(128,1)-p_term.log2()))\n",
    "    \n",
    "        if test:\n",
    "            # Greedy\n",
    "            term = torch.round(p_term).long()\n",
    "        else:\n",
    "            # Sample\n",
    "            term = torch.bernoulli(p_term).long()\n",
    "        \n",
    "        # Linguistic construction ----------------------------------\n",
    "        h = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,num_vocab])\n",
    "        \n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h,c) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h,c))\n",
    "            logit = self.ff_ling(h)\n",
    "            p_letter = F.softmax(logit,dim=2).view(self.batch_size,num_vocab)\n",
    "            \n",
    "            entropy_letter[:,i] = -1*(torch.sum(p_letter[i],0,keepdim=True) * torch.sum(p_letter[i],0,keepdim=True).log2())\n",
    "            \n",
    "            if test:\n",
    "                # Greedy\n",
    "                letter = p_letter.argmax(dim=1).view(self.batch_size,1)\n",
    "            else:\n",
    "                # Sample\n",
    "                letter = torch.polynomial(p_letter,1)\n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(letter,1)     \n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = torch.zeros(num_types,self.batch_size,max_item)\n",
    "        prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop= torch.zeros([self.batch_size,num_types])\n",
    "        \n",
    "        for i in range(num_types):\n",
    "            blah = F.sigmoid(self.policy_prop[i](h))\n",
    "            p_prop[i] = F.sigmoid(self.policy_prop[i](h))\n",
    "            \n",
    "            entropy_prop[:,i] = -1*(torch.sum(p_prop[i],1) * torch.sum(p_prop[i],1).log2())\n",
    "            if test:\n",
    "                # Greedy\n",
    "                prop[:,i] = p_prop[i].argmax(dim=1)\n",
    "            else:\n",
    "                # Sample\n",
    "                prop[0][i] = torch.multinomial(p_prop,1)\n",
    "            \n",
    "        entropy_prop = torch.sum(entropy_prop,1) # Entropy for exploration        \n",
    "\n",
    "        loss = torch.zeros(1,requires_grad=True)\n",
    "        \n",
    "        return (term,message,prop,loss)\n",
    "    \n",
    "net = combined_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3])\n"
     ]
    }
   ],
   "source": [
    "blah = net([x,y,z],True)\n",
    "\n",
    "print(blah[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/TH/generic/THTensorMath.c:343",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a317cbf33e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Actually play the game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_proposals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_proposals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-6306f42cf921>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, test)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Initial embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/anaconda3/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    106\u001b[0m         return F.embedding(\n\u001b[1;32m    107\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/TH/generic/THTensorMath.c:343"
     ]
    }
   ],
   "source": [
    "# Agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    \n",
    "# Train REINFORCE\n",
    "alpha = 0.001     # learning rate\n",
    "N_ep = 50   # Number of episodes\n",
    "num_games = 128 # Number of games per episode (batch size)\n",
    "\n",
    "# Initialize optimizer to update the DQN\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters(), alpha))\n",
    "\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Truncated Poisson sampling\n",
    "    N = np.random.poisson(lam,num_games) \n",
    "    N = np.minimum(N,max_N)\n",
    "    N = np.maximum(N,min_N)\n",
    "\n",
    "    # Setting\n",
    "    pool = create_item_pool(num_types, max_item, num_games) # Item pool\n",
    "    item_contexts = []\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool,utility],1))\n",
    "    \n",
    "    # Initialization\n",
    "    survivors = torch.ones(num_games).nonzero() # Everyone alive initially\n",
    "    prev_messages = torch.zeros(num_games,len_message).long() # Previous linguistic messages\n",
    "    prev_proposals = torch.zeros(num_games,num_types).long()   # Previous proposals\n",
    "    num_alive = len(survivors)\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N):\n",
    "        # Sieve\n",
    "        pool = pool[survivors]\n",
    "        prev_messages = prev_messages[survivors]\n",
    "        prev_proposals = prev_proposals[survivors]\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors]\n",
    "        \n",
    "        # Agent that is playing\n",
    "        Agent = Agents[i_turn % 2]             \n",
    "        item_context = item_contexts[i_turn % 2]\n",
    "        \n",
    "        # Actually play the game\n",
    "        term,prev_messages,prev_proposals,loss = Agent([item_context,prev_messages,prev_proposals], True)\n",
    "\n",
    "        # optimize\n",
    "        optimizer = optimizers[i_turn % 2]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Remove finished games\n",
    "        # In term, element = 1 means die\n",
    "        term_N = torch.from_numpy(1*(N <= i_turn)).view(num_alive,1)\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (((term+term_N)) == 0).nonzero().view(num_alive)\n",
    "        num_alive = len(survivors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_messages.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [   1],\n",
       "        [   2],\n",
       "        [   3],\n",
       "        [   4],\n",
       "        [   5],\n",
       "        [   6],\n",
       "        [   7],\n",
       "        [   8],\n",
       "        [   9],\n",
       "        [  10],\n",
       "        [  11],\n",
       "        [  12],\n",
       "        [  13],\n",
       "        [  14],\n",
       "        [  15],\n",
       "        [  16],\n",
       "        [  17],\n",
       "        [  18],\n",
       "        [  19],\n",
       "        [  20],\n",
       "        [  21],\n",
       "        [  22],\n",
       "        [  23],\n",
       "        [  24],\n",
       "        [  25],\n",
       "        [  26],\n",
       "        [  27],\n",
       "        [  28],\n",
       "        [  29],\n",
       "        [  30],\n",
       "        [  31],\n",
       "        [  32],\n",
       "        [  33],\n",
       "        [  34],\n",
       "        [  35],\n",
       "        [  36],\n",
       "        [  37],\n",
       "        [  38],\n",
       "        [  39],\n",
       "        [  40],\n",
       "        [  41],\n",
       "        [  42],\n",
       "        [  43],\n",
       "        [  44],\n",
       "        [  45],\n",
       "        [  46],\n",
       "        [  47],\n",
       "        [  48],\n",
       "        [  49],\n",
       "        [  50],\n",
       "        [  51],\n",
       "        [  52],\n",
       "        [  53],\n",
       "        [  54],\n",
       "        [  55],\n",
       "        [  56],\n",
       "        [  57],\n",
       "        [  58],\n",
       "        [  59],\n",
       "        [  60],\n",
       "        [  61],\n",
       "        [  62],\n",
       "        [  63],\n",
       "        [  64],\n",
       "        [  65],\n",
       "        [  66],\n",
       "        [  67],\n",
       "        [  68],\n",
       "        [  69],\n",
       "        [  70],\n",
       "        [  71],\n",
       "        [  72],\n",
       "        [  73],\n",
       "        [  74],\n",
       "        [  75],\n",
       "        [  76],\n",
       "        [  77],\n",
       "        [  78],\n",
       "        [  79],\n",
       "        [  80],\n",
       "        [  81],\n",
       "        [  82],\n",
       "        [  83],\n",
       "        [  84],\n",
       "        [  85],\n",
       "        [  86],\n",
       "        [  87],\n",
       "        [  88],\n",
       "        [  89],\n",
       "        [  90],\n",
       "        [  91],\n",
       "        [  92],\n",
       "        [  93],\n",
       "        [  94],\n",
       "        [  95],\n",
       "        [  96],\n",
       "        [  97],\n",
       "        [  98],\n",
       "        [  99],\n",
       "        [ 100],\n",
       "        [ 101],\n",
       "        [ 102],\n",
       "        [ 103],\n",
       "        [ 104],\n",
       "        [ 105],\n",
       "        [ 106],\n",
       "        [ 107],\n",
       "        [ 108],\n",
       "        [ 109],\n",
       "        [ 110],\n",
       "        [ 111],\n",
       "        [ 112],\n",
       "        [ 113],\n",
       "        [ 114],\n",
       "        [ 115],\n",
       "        [ 116],\n",
       "        [ 117],\n",
       "        [ 118],\n",
       "        [ 119],\n",
       "        [ 120],\n",
       "        [ 121],\n",
       "        [ 122],\n",
       "        [ 123],\n",
       "        [ 124],\n",
       "        [ 125],\n",
       "        [ 126],\n",
       "        [ 127]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
