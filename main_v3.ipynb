{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "v3 = This now trains, the test function was a poopyhead, i.e. I removed test.<br>\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 0\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 15\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 1000          # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab+1, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1) # Same encoder as item context       \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h1,c1) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h2,c2) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h3,c3) = self.lstm2(x3[i].view(1,self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],2).view(self.batch_size,-1)\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) \n",
    "        # Sample\n",
    "        term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "            letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)\n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.sigmoid(self.policy_prop[i](h)))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "            \n",
    "            # Sample\n",
    "            #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "            prop.append(torch.multinomial(p_prop[i],1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        #print(entropy_loss.size())\n",
    "        entropy_loss = entropy_loss.sum()\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "        \n",
    "\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "tensor(76)\n"
     ]
    }
   ],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z])\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "128\n",
      "tensor(54)\n",
      "74\n",
      "tensor(44)\n",
      "30\n",
      "tensor(16)\n",
      "14\n",
      "tensor(8)\n",
      "6\n",
      "tensor(3)\n",
      "3\n",
      "tensor(2)\n",
      "128\n",
      "tensor(60)\n",
      "68\n",
      "tensor(35)\n",
      "33\n",
      "tensor(12)\n",
      "21\n",
      "tensor(13)\n",
      "5\n",
      "tensor(2)\n",
      "3\n",
      "tensor(2)\n",
      "128\n",
      "tensor(56)\n",
      "72\n",
      "tensor(26)\n",
      "46\n",
      "tensor(17)\n",
      "29\n",
      "tensor(17)\n",
      "11\n",
      "tensor(6)\n",
      "4\n",
      "tensor(3)\n",
      "128\n",
      "tensor(46)\n",
      "82\n",
      "tensor(34)\n",
      "48\n",
      "tensor(16)\n",
      "32\n",
      "tensor(15)\n",
      "16\n",
      "tensor(8)\n",
      "7\n",
      "tensor(3)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(2)\n",
      "128\n",
      "tensor(47)\n",
      "81\n",
      "tensor(38)\n",
      "43\n",
      "tensor(16)\n",
      "27\n",
      "tensor(7)\n",
      "14\n",
      "tensor(8)\n",
      "5\n",
      "tensor(3)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(39)\n",
      "89\n",
      "tensor(39)\n",
      "50\n",
      "tensor(26)\n",
      "24\n",
      "tensor(5)\n",
      "17\n",
      "tensor(7)\n",
      "9\n",
      "tensor(5)\n",
      "2\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(35)\n",
      "93\n",
      "tensor(31)\n",
      "62\n",
      "tensor(25)\n",
      "37\n",
      "tensor(8)\n",
      "24\n",
      "tensor(11)\n",
      "9\n",
      "tensor(3)\n",
      "6\n",
      "tensor(3)\n",
      "3\n",
      "tensor(2)\n",
      "128\n",
      "tensor(39)\n",
      "89\n",
      "tensor(36)\n",
      "53\n",
      "tensor(19)\n",
      "34\n",
      "tensor(11)\n",
      "21\n",
      "tensor(8)\n",
      "11\n",
      "tensor(3)\n",
      "6\n",
      "tensor(3)\n",
      "3\n",
      "tensor(1)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(40)\n",
      "88\n",
      "tensor(27)\n",
      "61\n",
      "tensor(18)\n",
      "43\n",
      "tensor(12)\n",
      "25\n",
      "tensor(10)\n",
      "14\n",
      "tensor(3)\n",
      "10\n",
      "tensor(6)\n",
      "2\n",
      "tensor(2)\n",
      "128\n",
      "tensor(41)\n",
      "87\n",
      "tensor(20)\n",
      "67\n",
      "tensor(27)\n",
      "40\n",
      "tensor(12)\n",
      "25\n",
      "tensor(8)\n",
      "15\n",
      "tensor(5)\n",
      "8\n",
      "tensor(3)\n",
      "5\n",
      "tensor(0)\n",
      "5\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "128\n",
      "tensor(36)\n",
      "92\n",
      "tensor(23)\n",
      "69\n",
      "tensor(29)\n",
      "40\n",
      "tensor(14)\n",
      "22\n",
      "tensor(6)\n",
      "14\n",
      "tensor(3)\n",
      "10\n",
      "tensor(5)\n",
      "3\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(38)\n",
      "47\n",
      "tensor(22)\n",
      "25\n",
      "tensor(8)\n",
      "12\n",
      "tensor(3)\n",
      "9\n",
      "tensor(3)\n",
      "3\n",
      "tensor(0)\n",
      "2\n",
      "tensor(2)\n",
      "128\n",
      "tensor(54)\n",
      "74\n",
      "tensor(25)\n",
      "49\n",
      "tensor(15)\n",
      "34\n",
      "tensor(13)\n",
      "17\n",
      "tensor(8)\n",
      "8\n",
      "tensor(3)\n",
      "4\n",
      "tensor(3)\n",
      "128\n",
      "tensor(50)\n",
      "78\n",
      "tensor(22)\n",
      "56\n",
      "tensor(22)\n",
      "34\n",
      "tensor(13)\n",
      "20\n",
      "tensor(7)\n",
      "10\n",
      "tensor(2)\n",
      "8\n",
      "tensor(3)\n",
      "128\n",
      "tensor(42)\n",
      "86\n",
      "tensor(34)\n",
      "52\n",
      "tensor(21)\n",
      "31\n",
      "tensor(13)\n",
      "14\n",
      "tensor(2)\n",
      "12\n",
      "tensor(4)\n",
      "6\n",
      "tensor(2)\n",
      "3\n",
      "tensor(2)\n",
      "128\n",
      "tensor(51)\n",
      "77\n",
      "tensor(38)\n",
      "39\n",
      "tensor(13)\n",
      "26\n",
      "tensor(8)\n",
      "15\n",
      "tensor(11)\n",
      "4\n",
      "tensor(1)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(59)\n",
      "69\n",
      "tensor(25)\n",
      "44\n",
      "tensor(13)\n",
      "31\n",
      "tensor(10)\n",
      "19\n",
      "tensor(4)\n",
      "14\n",
      "tensor(3)\n",
      "10\n",
      "tensor(2)\n",
      "7\n",
      "tensor(1)\n",
      "5\n",
      "tensor(3)\n",
      "2\n",
      "tensor(0)\n",
      "128\n",
      "tensor(61)\n",
      "67\n",
      "tensor(21)\n",
      "46\n",
      "tensor(15)\n",
      "31\n",
      "tensor(13)\n",
      "17\n",
      "tensor(9)\n",
      "6\n",
      "tensor(4)\n",
      "2\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(52)\n",
      "76\n",
      "tensor(34)\n",
      "42\n",
      "tensor(20)\n",
      "22\n",
      "tensor(9)\n",
      "12\n",
      "tensor(4)\n",
      "6\n",
      "tensor(3)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(40)\n",
      "88\n",
      "tensor(35)\n",
      "53\n",
      "tensor(23)\n",
      "30\n",
      "tensor(9)\n",
      "16\n",
      "tensor(6)\n",
      "9\n",
      "tensor(3)\n",
      "6\n",
      "tensor(3)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(49)\n",
      "79\n",
      "tensor(27)\n",
      "52\n",
      "tensor(10)\n",
      "42\n",
      "tensor(19)\n",
      "20\n",
      "tensor(11)\n",
      "7\n",
      "tensor(1)\n",
      "6\n",
      "tensor(0)\n",
      "3\n",
      "tensor(2)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(46)\n",
      "82\n",
      "tensor(29)\n",
      "53\n",
      "tensor(21)\n",
      "32\n",
      "tensor(10)\n",
      "17\n",
      "tensor(5)\n",
      "11\n",
      "tensor(5)\n",
      "6\n",
      "tensor(1)\n",
      "2\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(47)\n",
      "81\n",
      "tensor(26)\n",
      "55\n",
      "tensor(16)\n",
      "39\n",
      "tensor(21)\n",
      "16\n",
      "tensor(7)\n",
      "5\n",
      "tensor(2)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(57)\n",
      "71\n",
      "tensor(28)\n",
      "43\n",
      "tensor(19)\n",
      "24\n",
      "tensor(9)\n",
      "11\n",
      "tensor(6)\n",
      "4\n",
      "tensor(2)\n",
      "2\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(52)\n",
      "76\n",
      "tensor(26)\n",
      "50\n",
      "tensor(19)\n",
      "31\n",
      "tensor(13)\n",
      "14\n",
      "tensor(7)\n",
      "7\n",
      "tensor(0)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(24)\n",
      "61\n",
      "tensor(22)\n",
      "39\n",
      "tensor(19)\n",
      "14\n",
      "tensor(9)\n",
      "4\n",
      "tensor(2)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(42)\n",
      "86\n",
      "tensor(33)\n",
      "53\n",
      "tensor(18)\n",
      "35\n",
      "tensor(14)\n",
      "18\n",
      "tensor(2)\n",
      "14\n",
      "tensor(8)\n",
      "4\n",
      "tensor(2)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(52)\n",
      "76\n",
      "tensor(31)\n",
      "45\n",
      "tensor(20)\n",
      "25\n",
      "tensor(9)\n",
      "13\n",
      "tensor(2)\n",
      "10\n",
      "tensor(4)\n",
      "6\n",
      "tensor(2)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(47)\n",
      "81\n",
      "tensor(29)\n",
      "52\n",
      "tensor(18)\n",
      "34\n",
      "tensor(9)\n",
      "21\n",
      "tensor(6)\n",
      "14\n",
      "tensor(7)\n",
      "5\n",
      "tensor(5)\n",
      "128\n",
      "tensor(51)\n",
      "77\n",
      "tensor(25)\n",
      "52\n",
      "tensor(21)\n",
      "31\n",
      "tensor(10)\n",
      "17\n",
      "tensor(4)\n",
      "11\n",
      "tensor(8)\n",
      "3\n",
      "tensor(2)\n",
      "128\n",
      "tensor(48)\n",
      "80\n",
      "tensor(29)\n",
      "51\n",
      "tensor(15)\n",
      "36\n",
      "tensor(12)\n",
      "17\n",
      "tensor(10)\n",
      "5\n",
      "tensor(1)\n",
      "3\n",
      "tensor(0)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(51)\n",
      "77\n",
      "tensor(27)\n",
      "50\n",
      "tensor(24)\n",
      "26\n",
      "tensor(9)\n",
      "14\n",
      "tensor(7)\n",
      "5\n",
      "tensor(2)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(46)\n",
      "82\n",
      "tensor(35)\n",
      "47\n",
      "tensor(20)\n",
      "27\n",
      "tensor(11)\n",
      "14\n",
      "tensor(7)\n",
      "7\n",
      "tensor(4)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(53)\n",
      "75\n",
      "tensor(29)\n",
      "46\n",
      "tensor(15)\n",
      "31\n",
      "tensor(12)\n",
      "18\n",
      "tensor(7)\n",
      "10\n",
      "tensor(6)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(47)\n",
      "81\n",
      "tensor(27)\n",
      "54\n",
      "tensor(18)\n",
      "36\n",
      "tensor(12)\n",
      "20\n",
      "tensor(9)\n",
      "11\n",
      "tensor(4)\n",
      "6\n",
      "tensor(2)\n",
      "128\n",
      "tensor(46)\n",
      "82\n",
      "tensor(26)\n",
      "56\n",
      "tensor(25)\n",
      "31\n",
      "tensor(9)\n",
      "20\n",
      "tensor(8)\n",
      "9\n",
      "tensor(5)\n",
      "3\n",
      "tensor(3)\n",
      "128\n",
      "tensor(54)\n",
      "74\n",
      "tensor(19)\n",
      "55\n",
      "tensor(20)\n",
      "35\n",
      "tensor(11)\n",
      "20\n",
      "tensor(8)\n",
      "10\n",
      "tensor(1)\n",
      "6\n",
      "tensor(1)\n",
      "5\n",
      "tensor(0)\n",
      "4\n",
      "tensor(4)\n",
      "128\n",
      "tensor(42)\n",
      "86\n",
      "tensor(28)\n",
      "58\n",
      "tensor(18)\n",
      "40\n",
      "tensor(12)\n",
      "24\n",
      "tensor(9)\n",
      "12\n",
      "tensor(3)\n",
      "8\n",
      "tensor(5)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(50)\n",
      "78\n",
      "tensor(37)\n",
      "41\n",
      "tensor(14)\n",
      "27\n",
      "tensor(14)\n",
      "12\n",
      "tensor(7)\n",
      "5\n",
      "tensor(2)\n",
      "3\n",
      "tensor(2)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(54)\n",
      "74\n",
      "tensor(39)\n",
      "35\n",
      "tensor(9)\n",
      "26\n",
      "tensor(7)\n",
      "17\n",
      "tensor(7)\n",
      "8\n",
      "tensor(2)\n",
      "5\n",
      "tensor(3)\n",
      "128\n",
      "tensor(47)\n",
      "81\n",
      "tensor(23)\n",
      "58\n",
      "tensor(21)\n",
      "37\n",
      "tensor(12)\n",
      "22\n",
      "tensor(10)\n",
      "9\n",
      "tensor(3)\n",
      "5\n",
      "tensor(1)\n",
      "2\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(37)\n",
      "48\n",
      "tensor(14)\n",
      "34\n",
      "tensor(14)\n",
      "16\n",
      "tensor(4)\n",
      "10\n",
      "tensor(5)\n",
      "4\n",
      "tensor(2)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(51)\n",
      "77\n",
      "tensor(33)\n",
      "44\n",
      "tensor(17)\n",
      "27\n",
      "tensor(9)\n",
      "15\n",
      "tensor(5)\n",
      "9\n",
      "tensor(4)\n",
      "3\n",
      "tensor(0)\n",
      "3\n",
      "tensor(2)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(55)\n",
      "73\n",
      "tensor(29)\n",
      "44\n",
      "tensor(16)\n",
      "28\n",
      "tensor(11)\n",
      "14\n",
      "tensor(4)\n",
      "10\n",
      "tensor(7)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(48)\n",
      "80\n",
      "tensor(30)\n",
      "50\n",
      "tensor(15)\n",
      "35\n",
      "tensor(10)\n",
      "23\n",
      "tensor(12)\n",
      "10\n",
      "tensor(6)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(49)\n",
      "79\n",
      "tensor(26)\n",
      "53\n",
      "tensor(27)\n",
      "26\n",
      "tensor(7)\n",
      "16\n",
      "tensor(6)\n",
      "8\n",
      "tensor(3)\n",
      "3\n",
      "tensor(2)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(50)\n",
      "78\n",
      "tensor(24)\n",
      "54\n",
      "tensor(19)\n",
      "35\n",
      "tensor(7)\n",
      "24\n",
      "tensor(10)\n",
      "12\n",
      "tensor(5)\n",
      "4\n",
      "tensor(2)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(51)\n",
      "77\n",
      "tensor(26)\n",
      "51\n",
      "tensor(26)\n",
      "25\n",
      "tensor(13)\n",
      "11\n",
      "tensor(2)\n",
      "6\n",
      "tensor(0)\n",
      "6\n",
      "tensor(1)\n",
      "3\n",
      "tensor(2)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(44)\n",
      "84\n",
      "tensor(29)\n",
      "55\n",
      "tensor(23)\n",
      "32\n",
      "tensor(8)\n",
      "18\n",
      "tensor(8)\n",
      "9\n",
      "tensor(1)\n",
      "6\n",
      "tensor(1)\n",
      "4\n",
      "tensor(3)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(42)\n",
      "43\n",
      "tensor(14)\n",
      "29\n",
      "tensor(11)\n",
      "16\n",
      "tensor(6)\n",
      "8\n",
      "tensor(1)\n",
      "6\n",
      "tensor(2)\n",
      "3\n",
      "tensor(3)\n",
      "128\n",
      "tensor(50)\n",
      "78\n",
      "tensor(24)\n",
      "54\n",
      "tensor(23)\n",
      "31\n",
      "tensor(13)\n",
      "15\n",
      "tensor(10)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(1)\n",
      "128\n",
      "tensor(48)\n",
      "80\n",
      "tensor(32)\n",
      "48\n",
      "tensor(14)\n",
      "34\n",
      "tensor(16)\n",
      "15\n",
      "tensor(9)\n",
      "5\n",
      "tensor(4)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(45)\n",
      "83\n",
      "tensor(33)\n",
      "50\n",
      "tensor(18)\n",
      "32\n",
      "tensor(12)\n",
      "19\n",
      "tensor(8)\n",
      "11\n",
      "tensor(4)\n",
      "3\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(41)\n",
      "87\n",
      "tensor(30)\n",
      "57\n",
      "tensor(21)\n",
      "36\n",
      "tensor(10)\n",
      "17\n",
      "tensor(8)\n",
      "9\n",
      "tensor(3)\n",
      "5\n",
      "tensor(3)\n",
      "2\n",
      "tensor(1)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(30)\n",
      "55\n",
      "tensor(17)\n",
      "38\n",
      "tensor(13)\n",
      "21\n",
      "tensor(9)\n",
      "11\n",
      "tensor(3)\n",
      "8\n",
      "tensor(2)\n",
      "6\n",
      "tensor(3)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(47)\n",
      "81\n",
      "tensor(30)\n",
      "51\n",
      "tensor(17)\n",
      "34\n",
      "tensor(16)\n",
      "13\n",
      "tensor(4)\n",
      "7\n",
      "tensor(0)\n",
      "3\n",
      "tensor(2)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(41)\n",
      "87\n",
      "tensor(43)\n",
      "44\n",
      "tensor(21)\n",
      "23\n",
      "tensor(6)\n",
      "14\n",
      "tensor(6)\n",
      "7\n",
      "tensor(3)\n",
      "4\n",
      "tensor(1)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(55)\n",
      "73\n",
      "tensor(25)\n",
      "48\n",
      "tensor(20)\n",
      "28\n",
      "tensor(7)\n",
      "17\n",
      "tensor(4)\n",
      "10\n",
      "tensor(5)\n",
      "5\n",
      "tensor(2)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(49)\n",
      "79\n",
      "tensor(26)\n",
      "53\n",
      "tensor(22)\n",
      "31\n",
      "tensor(10)\n",
      "18\n",
      "tensor(5)\n",
      "9\n",
      "tensor(2)\n",
      "4\n",
      "tensor(3)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(30)\n",
      "55\n",
      "tensor(22)\n",
      "33\n",
      "tensor(11)\n",
      "18\n",
      "tensor(9)\n",
      "8\n",
      "tensor(5)\n",
      "3\n",
      "tensor(0)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(55)\n",
      "73\n",
      "tensor(24)\n",
      "49\n",
      "tensor(17)\n",
      "32\n",
      "tensor(13)\n",
      "14\n",
      "tensor(7)\n",
      "5\n",
      "tensor(5)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(29)\n",
      "56\n",
      "tensor(20)\n",
      "36\n",
      "tensor(13)\n",
      "20\n",
      "tensor(4)\n",
      "14\n",
      "tensor(6)\n",
      "7\n",
      "tensor(1)\n",
      "3\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(44)\n",
      "84\n",
      "tensor(37)\n",
      "47\n",
      "tensor(24)\n",
      "23\n",
      "tensor(7)\n",
      "15\n",
      "tensor(5)\n",
      "9\n",
      "tensor(5)\n",
      "4\n",
      "tensor(1)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(44)\n",
      "84\n",
      "tensor(29)\n",
      "55\n",
      "tensor(22)\n",
      "33\n",
      "tensor(16)\n",
      "14\n",
      "tensor(5)\n",
      "7\n",
      "tensor(4)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(49)\n",
      "79\n",
      "tensor(32)\n",
      "47\n",
      "tensor(14)\n",
      "33\n",
      "tensor(8)\n",
      "19\n",
      "tensor(11)\n",
      "6\n",
      "tensor(2)\n",
      "3\n",
      "tensor(1)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(40)\n",
      "88\n",
      "tensor(30)\n",
      "58\n",
      "tensor(23)\n",
      "35\n",
      "tensor(12)\n",
      "19\n",
      "tensor(10)\n",
      "8\n",
      "tensor(3)\n",
      "5\n",
      "tensor(2)\n",
      "3\n",
      "tensor(2)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(52)\n",
      "76\n",
      "tensor(29)\n",
      "47\n",
      "tensor(17)\n",
      "30\n",
      "tensor(10)\n",
      "18\n",
      "tensor(6)\n",
      "9\n",
      "tensor(5)\n",
      "3\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(45)\n",
      "83\n",
      "tensor(36)\n",
      "47\n",
      "tensor(17)\n",
      "30\n",
      "tensor(12)\n",
      "15\n",
      "tensor(3)\n",
      "9\n",
      "tensor(4)\n",
      "5\n",
      "tensor(2)\n",
      "2\n",
      "tensor(0)\n",
      "128\n",
      "tensor(45)\n",
      "83\n",
      "tensor(35)\n",
      "48\n",
      "tensor(23)\n",
      "25\n",
      "tensor(10)\n",
      "11\n",
      "tensor(2)\n",
      "7\n",
      "tensor(3)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(53)\n",
      "75\n",
      "tensor(29)\n",
      "46\n",
      "tensor(16)\n",
      "30\n",
      "tensor(13)\n",
      "14\n",
      "tensor(9)\n",
      "5\n",
      "tensor(1)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(45)\n",
      "83\n",
      "tensor(32)\n",
      "51\n",
      "tensor(26)\n",
      "25\n",
      "tensor(9)\n",
      "13\n",
      "tensor(4)\n",
      "9\n",
      "tensor(4)\n",
      "3\n",
      "tensor(0)\n",
      "3\n",
      "tensor(1)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(0)\n",
      "128\n",
      "tensor(50)\n",
      "78\n",
      "tensor(30)\n",
      "48\n",
      "tensor(18)\n",
      "30\n",
      "tensor(12)\n",
      "14\n",
      "tensor(5)\n",
      "6\n",
      "tensor(0)\n",
      "4\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(49)\n",
      "79\n",
      "tensor(38)\n",
      "41\n",
      "tensor(17)\n",
      "24\n",
      "tensor(12)\n",
      "8\n",
      "tensor(2)\n",
      "5\n",
      "tensor(1)\n",
      "3\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(44)\n",
      "84\n",
      "tensor(34)\n",
      "50\n",
      "tensor(17)\n",
      "33\n",
      "tensor(12)\n",
      "17\n",
      "tensor(6)\n",
      "10\n",
      "tensor(4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "tensor(3)\n",
      "2\n",
      "tensor(1)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(24)\n",
      "61\n",
      "tensor(24)\n",
      "37\n",
      "tensor(16)\n",
      "17\n",
      "tensor(5)\n",
      "11\n",
      "tensor(5)\n",
      "3\n",
      "tensor(0)\n",
      "3\n",
      "tensor(2)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(39)\n",
      "89\n",
      "tensor(29)\n",
      "60\n",
      "tensor(21)\n",
      "39\n",
      "tensor(14)\n",
      "17\n",
      "tensor(10)\n",
      "6\n",
      "tensor(3)\n",
      "2\n",
      "tensor(0)\n",
      "2\n",
      "tensor(1)\n",
      "1\n",
      "tensor(1)\n",
      "128\n",
      "tensor(47)\n",
      "81\n",
      "tensor(31)\n",
      "50\n",
      "tensor(18)\n",
      "32\n",
      "tensor(13)\n",
      "17\n",
      "tensor(6)\n",
      "11\n",
      "tensor(5)\n",
      "5\n",
      "tensor(1)\n",
      "3\n",
      "tensor(1)\n",
      "1\n",
      "tensor(0)\n",
      "1\n",
      "tensor(0)\n",
      "128\n",
      "tensor(43)\n",
      "85\n",
      "tensor(29)\n",
      "56\n",
      "tensor(18)\n",
      "38\n",
      "tensor(14)\n",
      "22\n",
      "tensor(11)\n",
      "11\n",
      "tensor(5)\n",
      "6\n",
      "tensor(2)\n",
      "3\n",
      "tensor(1)\n",
      "128\n",
      "tensor(45)\n",
      "83\n",
      "tensor(28)\n",
      "55\n",
      "tensor(18)\n",
      "37\n",
      "tensor(10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4cda85d6a0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Play the game -------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_proposals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_alive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mentropy_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e9bc233b3fc8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch_size)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0membedded_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_ling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_ling\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_ling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_letter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_ling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_ling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_ling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_ling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mp_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            #losses[id_1] += rl1\n",
    "            #losses[id_2] += rl2\n",
    "            \n",
    "        # Accumulate entropy loss\n",
    "        losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "        losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(losses[i])\n",
    "        #print(Agents[i].ff_ling.weight.grad)\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_sum_refreg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
