{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 1\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 15\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 100              # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab+1, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, test, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1) # Same encoder as item context\n",
    "        \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h1,c1) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h2,c2) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h3,c3) = self.lstm2(x3[i].view(1,self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],2).squeeze()\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term_tensor = -(p_term * (p_term+1e-8).log()) - ((one_tensor-p_term) * (one_tensor-p_term+1e-8).log())\n",
    "        entropy_term = torch.sum(entropy_term_tensor)\n",
    "        #print(entropy_term)\n",
    "        \n",
    "        if test:\n",
    "            # Greedy\n",
    "            term = torch.round(p_term).long()\n",
    "        else:\n",
    "            # Sample\n",
    "            term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                letter = p_letter.argmax(dim=1).view(self.batch_size,1).long()\n",
    "            else:\n",
    "                # Sample\n",
    "                letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter)     \n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.sigmoid(self.policy_prop[i](h)))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log())\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "\n",
    "            if test:\n",
    "                # Greedy\n",
    "                #prop[:,i] = p_prop[i].argmax(dim=1)\n",
    "                prop.append(p_prop[i].argmax(dim=1))\n",
    "            else:\n",
    "                # Sample\n",
    "                #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "                prop.append(torch.multinomial(p_prop,1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = sum(entropy_prop_list) # Entropy for exploration\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = torch.sum(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        self.log_p = log_p_term + log_p_letter + log_p_prop\n",
    "        \n",
    "        #if entropy_loss != entropy_loss:\n",
    "        #    print(entropy_term)\n",
    "        #    print(entropy_prop)\n",
    "        #    print(entropy_letter)\n",
    "\n",
    "        return (term,message,prop, entropy_loss, log_p_term,log_p_letter,log_p_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z],True)\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-10: 0.9243898391723633s\n",
      "Runtime for episodes 10-20: 0.6517608165740967s\n",
      "Runtime for episodes 20-30: 0.7313787937164307s\n",
      "Runtime for episodes 30-40: 0.6415622234344482s\n",
      "Runtime for episodes 40-50: 0.5799899101257324s\n",
      "Runtime for episodes 50-60: 0.6134414672851562s\n",
      "Runtime for episodes 60-70: 0.49936652183532715s\n",
      "Runtime for episodes 70-80: 1.039344072341919s\n",
      "Runtime for episodes 80-90: 0.5473470687866211s\n",
      "End ------------------\n",
      "Total runtime: 6.815549612045288s\n"
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            # Initialize log_p for REINFORCE\n",
    "            Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss, lt,ll,lp = Agent([item_context, prev_messages, prev_proposals], True, num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        # Gradient descent -----------------------------------------------------------\n",
    "        \n",
    "        for i in range(num_agents):\n",
    "            # optimize\n",
    "            loss = reward_losses[i]-entropy_losses[i]\n",
    "            optimizers[i].zero_grad()\n",
    "            loss.backward()\n",
    "            #print(Agents[i].ff_ling.weight.grad)\n",
    "            optimizers[i].step()\n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhqQAAGhICgCAhqQAAGhICgCA5gcYc1f7AjqrRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd26b66dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "#plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
