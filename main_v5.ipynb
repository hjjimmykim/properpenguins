{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "v3 = This now trains, the test function was a poopyhead, i.e. I removed test.<br>\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:29.764702Z",
     "start_time": "2018-06-04T23:56:28.573172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 0\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 15\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func, rewards_func_prosocial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:31.314343Z",
     "start_time": "2018-06-04T23:56:31.284455Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 3000            # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.001       # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.05        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Reward Scheme\n",
    "social  = 0            # 0 = selfish | 1 = prosocial   \n",
    "\n",
    "# Channels \n",
    "enable_message = 1     # 0 = Off | 1 = On\n",
    "enable_proposal = 1\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:33.162399Z",
     "start_time": "2018-06-04T23:56:32.755139Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 1, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab, embedding_dim)\n",
    "        \n",
    "        self.encoder3 = nn.Embedding(num_vocab, embedding_dim)\n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        if enable_message + enable_proposal == 2:\n",
    "            self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        elif enable_message + enable_proposal == 1:\n",
    "            self.ff = nn.Linear(2*embedding_dim, embedding_dim)\n",
    "        elif enable_message + enable_proposal == 0:\n",
    "            self.ff = nn.Linear(1*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1)\n",
    "        x2 = self.encoder2(x2)\n",
    "        x3 = self.encoder1(x3) # Same encoder as item context       \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "        for i in range(x1.size()[1]):\n",
    "            (h1,c1) = self.lstm1(x1[:,i].view(self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[1]):\n",
    "            (h2,c2) = self.lstm2(x2[:,i].view(self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[1]):\n",
    "            (h3,c3) = self.lstm3(x3[:,i].view(self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "        \n",
    "        # Concatenate side-by-side based on what channels are open\n",
    "        if enable_message == 1 and enable_proposal == 1:\n",
    "            h = torch.cat([x1_encoded,x2_encoded,x3_encoded],1).view(self.batch_size,-1)\n",
    "        elif enable_message == 1 and enable_proposal == 0:\n",
    "            h = torch.cat([x1_encoded,x2_encoded],1).view(self.batch_size,-1)\n",
    "        elif enable_message == 0 and enable_proposal == 1:\n",
    "            h = torch.cat([x1_encoded,x3_encoded],1).view(self.batch_size,-1)\n",
    "        elif enable_message == 0 and enable_proposal == 0:\n",
    "            h = x1_encoded\n",
    "            \n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) - (one_tensor-p_term) * ((one_tensor-p_term)+1e-8).log()\n",
    "        # Sample\n",
    "        term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "        # Linguistic construction ----------------------------------\n",
    "        if enable_message == 1:\n",
    "            h_ling = h.clone().view(self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "            c_ling = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell state\n",
    "            letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "            entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                c_ling = c_ling.cuda()\n",
    "                letter = letter.cuda()\n",
    "                entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "            # log p for REINFORCE \n",
    "            log_p_letter = torch.zeros([self.batch_size,1])\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "            message = torch.zeros(self.batch_size,len_message) # Message\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                message = message.cuda()\n",
    "            for i in range(len_message):\n",
    "                embedded_letter = self.encoder3(letter)\n",
    "\n",
    "                h_ling,c_ling = self.policy_ling(embedded_letter.view(self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "                logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "                p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "                entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "                letter = torch.multinomial(p_letter,1).long()\n",
    "\n",
    "                # Gather the probabilities for the letters we've picked\n",
    "                probs = torch.gather(p_letter, 1, letter)\n",
    "                log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "                message[:,i] = letter.squeeze()\n",
    "            \n",
    "            message = message.long()\n",
    "            entropy_letter = torch.sum(entropy_letter,1,keepdim=True)\n",
    "\n",
    "        else:\n",
    "            message = torch.zeros(self.batch_size,len_message).long()\n",
    "            entropy_letter = torch.zeros(self.batch_size,1).float()\n",
    "            log_p_letter = torch.zeros(self.batch_size,1).float()\n",
    "            \n",
    "        #print(message)\n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        if enable_proposal == 1:\n",
    "            p_prop = []\n",
    "            prop = []\n",
    "            entropy_prop_list = [0,0,0]\n",
    "        \n",
    "            # log p for REINFORCE \n",
    "            log_p_prop = torch.zeros([self.batch_size,1])\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "            for i in range(num_types):\n",
    "                p_prop.append(F.softmax(self.policy_prop[i](h),dim=1))\n",
    "            \n",
    "                entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "                p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "            \n",
    "                # Sample\n",
    "                prop.append(torch.multinomial(p_prop[i],1))\n",
    "                \n",
    "                # Gather the probabilities for the letters we've picked\n",
    "                probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "                log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "    \n",
    "            prop = torch.stack(prop).transpose(0,1)\n",
    "            entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "        \n",
    "        else:\n",
    "            prop = torch.zeros(self.batch_size,num_types,1).long()\n",
    "            entropy_prop = torch.zeros(self.batch_size,1).float()\n",
    "            log_p_prop = torch.zeros(self.batch_size,1).float()\n",
    "\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        entropy_loss = entropy_loss.sum()\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:36.432544Z",
     "start_time": "2018-06-04T23:56:36.289248Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z])\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-300: 169.69451904296875s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-ecb4f55d2521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;31m#print(Agents[i].policy_term.weight.grad.sum())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents+1)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "    \n",
    "total_r_list = []\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    #print(i_ep, '-----------------------------------------------------')\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    total_reward_sums = 0\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        utility_max = []\n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "        losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "        losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            utility_max = np.maximum(utility_1,utility_2)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func_prosocial(share_1, share_2, utility_1, utility_2, pool_12, log_p_1, baselines[-1], utility_max)\n",
    "            r2, rl2 = rewards_func_prosocial(share_1, share_2, utility_1, utility_2, pool_12, log_p_2, baselines[-1], utility_max)\n",
    "            \n",
    "            # Calculate total reward\n",
    "            total_reward = r1\n",
    "            total_reward_sums = total_reward_sums +  total_reward.sum()\n",
    "           \n",
    "            # Calculate social reward \n",
    "            if social == 0:\n",
    "                r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "                r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(Agents[i].policy_term.weight.grad.sum())\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "    \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "            \n",
    "    #Calculate total reward\n",
    "    total_r_mean = total_reward_sums/num_games\n",
    "    if (i_ep % ep_record == 0):\n",
    "        total_r_list.append(total_r_mean)\n",
    "    \n",
    "    # Update prosocial baseline\n",
    "    baselines[-1] = smoothing_const * baselines[-1] + (1-smoothing_const)*r_mean\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ea392b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.plot(epoch_list,total_r_list, label='Total Reward')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_sum_refreg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.cat([x1_encoded,x3_encoded],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
