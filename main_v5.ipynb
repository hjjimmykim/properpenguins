{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "v3 = This now trains, the test function was a poopyhead, i.e. I removed test.<br>\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:29.764702Z",
     "start_time": "2018-06-04T23:56:28.573172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 0\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 15\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func, rewards_func_prosocial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:31.314343Z",
     "start_time": "2018-06-04T23:56:31.284455Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 3000            # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001       # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Reward Scheme\n",
    "social  = 1            # 0 = selfish | 1 = prosocial     \n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:33.162399Z",
     "start_time": "2018-06-04T23:56:32.755139Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 1, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab, embedding_dim)\n",
    "        \n",
    "        self.encoder3 = nn.Embedding(num_vocab, embedding_dim)\n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1)\n",
    "        x2 = self.encoder2(x2)\n",
    "        x3 = self.encoder1(x3) # Same encoder as item context       \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "        for i in range(x1.size()[1]):\n",
    "            (h1,c1) = self.lstm1(x1[:,i].view(self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[1]):\n",
    "            (h2,c2) = self.lstm2(x2[:,i].view(self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[1]):\n",
    "            (h3,c3) = self.lstm3(x3[:,i].view(self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],1).view(self.batch_size,-1)\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) - (one_tensor-p_term) * ((one_tensor-p_term)+1e-8).log()\n",
    "        # Sample\n",
    "        term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder3(letter)\n",
    "\n",
    "            h_ling,c_ling = self.policy_ling(embedded_letter.view(self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "            letter = torch.multinomial(p_letter,1).long()\n",
    "#             print(\"utterance\")\n",
    "#             print(p_letter)\n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)\n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.softmax(self.policy_prop[i](h),dim=1))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "            \n",
    "            # Sample\n",
    "            #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "            prop.append(torch.multinomial(p_prop[i],1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "    \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        #print(entropy_loss.size())\n",
    "        entropy_loss = entropy_loss.sum()\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:36.432544Z",
     "start_time": "2018-06-04T23:56:36.289248Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z])\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-300: 87.99601101875305s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-eff2ff04ce43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Play the game -------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_proposals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_alive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mentropy_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-236-83e5121f6150>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch_size)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Termination -----------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mp_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_term\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baselines = 0 # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    #print(i_ep, '-----------------------------------------------------')\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        utility_max = []\n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "        losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "        losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            utility_max = np.maximum(utility_1,utility_2)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            if social == 0:\n",
    "                r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines)\n",
    "                r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines)\n",
    "            else:\n",
    "                r1, rl1 = rewards_func_prosocial(share_1, share_2, utility_1, utility_2, pool_12, log_p_1, baselines, utility_max)\n",
    "                r2, rl2 = rewards_func_prosocial(share_1, share_2, utility_1, utility_2, pool_12, log_p_2, baselines, utility_max)\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate entropy loss\n",
    "            #losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "            #losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "            \n",
    "        \n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(Agents[i].policy_term.weight.grad.sum())\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines = smoothing_const * baselines + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQQz9pwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fd958d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_sum_refreg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0,max_item,[3,2]).long()\n",
    "y = torch.randint(0,num_vocab,[3,2]).long()\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "np.maximum(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.maximum(np.zeros(6),np.zeros(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
