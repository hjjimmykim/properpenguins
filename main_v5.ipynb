{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "v3 = This now trains, the test function was a poopyhead, i.e. I removed test.<br>\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:29.764702Z",
     "start_time": "2018-06-04T23:56:28.573172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 0\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 15\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func, rewards_func_prosocial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:31.314343Z",
     "start_time": "2018-06-04T23:56:31.284455Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 3000            # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001       # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Reward Scheme\n",
    "social  = 0            # 0 = selfish | 1 = prosocial     \n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:33.162399Z",
     "start_time": "2018-06-04T23:56:32.755139Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 1, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab, embedding_dim)\n",
    "        \n",
    "        self.encoder3 = nn.Embedding(num_vocab, embedding_dim)\n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTMCell(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=embedding_dim\n",
    "        )\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1)\n",
    "        x2 = self.encoder2(x2)\n",
    "        x3 = self.encoder1(x3) # Same encoder as item context       \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "        for i in range(x1.size()[1]):\n",
    "            (h1,c1) = self.lstm1(x1[:,i].view(self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[1]):\n",
    "            (h2,c2) = self.lstm2(x2[:,i].view(self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[1]):\n",
    "            (h3,c3) = self.lstm3(x3[:,i].view(self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],1).view(self.batch_size,-1)\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) - (one_tensor-p_term) * ((one_tensor-p_term)+1e-8).log()\n",
    "        # Sample\n",
    "        term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder3(letter)\n",
    "\n",
    "            h_ling,c_ling = self.policy_ling(embedded_letter.view(self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "            letter = torch.multinomial(p_letter,1).long()\n",
    "#             print(\"utterance\")\n",
    "#             print(p_letter)\n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)\n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.softmax(self.policy_prop[i](h),dim=1))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "            \n",
    "            # Sample\n",
    "            #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "            prop.append(torch.multinomial(p_prop[i],1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "    \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        #print(entropy_loss.size())\n",
    "        entropy_loss = entropy_loss.sum()\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T23:56:36.432544Z",
     "start_time": "2018-06-04T23:56:36.289248Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z])\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-300: 117.95452618598938s\n",
      "Runtime for episodes 300-600: 132.3318817615509s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-4ddce6cf1c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;31m#print(Agents[i].policy_term.weight.grad.sum())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents+1)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    #print(i_ep, '-----------------------------------------------------')\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        utility_max = []\n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "        losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "        losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            utility_max = np.maximum(utility_1,utility_2)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            if social == 0:\n",
    "                r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "                r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            else:\n",
    "                r1, rl1 = rewards_func_prosocial(share_1, share_2, utility_1, utility_2, pool_12, log_p_1, baselines[-1], utility_max)\n",
    "                r2, rl2 = rewards_func_prosocial(share_1, share_2, utility_1, utility_2, pool_12, log_p_2, baselines[-1], utility_max)\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate entropy loss\n",
    "            #losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "            #losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            losses[id_1] += rl1\n",
    "            losses[id_2] += rl2\n",
    "            \n",
    "        \n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(Agents[i].policy_term.weight.grad.sum())\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "    \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "            \n",
    "    # Update prosocial baseline\n",
    "    baselines[-1] = smoothing_const * baselines[-1] + (1-smoothing_const)*r_mean\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117715160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_sum_refreg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randint(0,max_item,[3,2]).long()\n",
    "y = torch.randint(0,num_vocab,[3,2]).long()\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "np.maximum(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.maximum(np.zeros(6),np.zeros(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.zeros(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
