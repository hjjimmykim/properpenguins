{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "v3 = This now trains, the test function was a poopyhead, i.e. I removed test.<br>\n",
    "\n",
    "All the logarithms used are base 2. <br>\n",
    "Assumes 2 self-interested agents alternating turns. <br>\n",
    "Baseline (1 for each agent) gets updated after each episode ends (see corpses). <br>\n",
    "Rewards only possible at the end of each game. <br>\n",
    "Uses same (numerical) encoder for both item context and proposal. Reference code uses 3 distinct ones. It also has max_utility = num_types instead of 10 for us.<br>\n",
    "Check how message policy works again; paper seemed to imply that each output of the lstm is a letter. (we take the hidden output and make a probability over letters out of it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# cuda\n",
    "use_cuda = 1\n",
    "\n",
    "# Random seeds for testing\n",
    "num_seed = 15\n",
    "torch.manual_seed(num_seed)\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    torch.cuda.manual_seed(num_seed)\n",
    "np.random.seed(num_seed)\n",
    "\n",
    "# Utility functions\n",
    "from utility import truncated_poisson_sampling, create_item_pool, create_agent_utility, rewards_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Game setup\n",
    "num_agents = 2         # Number of agents playing the game\n",
    "num_types = 3          # Number of item types\n",
    "max_item = 5           # Maximum number of each item in a pool\n",
    "max_utility = 5       # Maximum utility value for agents\n",
    "\n",
    "# Turn sampling\n",
    "lam = 7                # Poisson parameter\n",
    "max_N = 10             # Maximum number of turns\n",
    "min_N = 4              # Minimum number of turns\n",
    "\n",
    "# Linguistic channel\n",
    "num_vocab = 10         # Symbol vocabulary size for linguistic channel\n",
    "len_message = 6        # Linguistic message length\n",
    "\n",
    "# Training\n",
    "alpha = 0.001          # learning rate\n",
    "N_ep = 100          # Number of episodes\n",
    "num_games = 128        # Number of games per episode (batch size)\n",
    "\n",
    "# Appendix\n",
    "lambda1 = 0.05         # Entropy regularizer for pi_term\n",
    "lambda2 = 0.0001        # Entropy regularizer for pi_utt\n",
    "lambda3 = 0.005        # Entropy regularizer for pi_prop\n",
    "smoothing_const = 0.7  # Smoothing constant for the exponential moving average baseline\n",
    "\n",
    "# Miscellaneous\n",
    "ep_time = int(max(1,N_ep/10))         # Print time every ep_time episodes\n",
    "ep_record = int(max(1,N_ep/1000))        # Record training curve every ep_record episodes\n",
    "save_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class combined_policy(nn.Module):\n",
    "    def __init__(self, embedding_dim = 100, batch_size = 128, num_layers = 1, bias = True, batch_first = False, dropout = 0, bidirectional = False):\n",
    "        super(combined_policy, self).__init__()\n",
    "        # Save variables\n",
    "        self.embedding_dim = embedding_dim # Hidden layer dimensions\n",
    "        self.batch_size = batch_size       # Batch size (updated every forward pass)\n",
    "        self.log_p = torch.zeros([batch_size,1], requires_grad=True)                     # Store policy log likelihood for REINFORCE\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            self.log_p = self.log_p.cuda()\n",
    "        \n",
    "        # Encoding -------------------------------------------------------------\n",
    "        \n",
    "        # Numerical encoder\n",
    "        self.encoder1 = nn.Embedding(max_utility+1, embedding_dim)\n",
    "        # Linguistic encoder\n",
    "        self.encoder2 = nn.Embedding(num_vocab, embedding_dim)\n",
    "        \n",
    "        # Item context LSTM\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Linguistic LSTM\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        # Proposal LSTM\n",
    "        self.lstm3 = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        \n",
    "        # Outputs of the 3 LSTMS get concatenated together\n",
    "        \n",
    "        # Feed-forward\n",
    "        self.ff = nn.Linear(3*embedding_dim, embedding_dim)\n",
    "        \n",
    "        # Output of feed-forward is the input for the policy networks\n",
    "        \n",
    "        # Policy ---------------------------------------------------------------\n",
    "        \n",
    "        # Termination policy\n",
    "        self.policy_term = nn.Linear(embedding_dim, 1)\n",
    "        # Linguistic policy\n",
    "        self.policy_ling = nn.LSTM(embedding_dim, embedding_dim, num_layers, bias, batch_first, dropout, bidirectional)\n",
    "        self.ff_ling = nn.Linear(embedding_dim, num_vocab)\n",
    "        # Proposal policies\n",
    "        self.policy_prop = nn.ModuleList([nn.Linear(embedding_dim, max_item+1) for i in range(num_types)])\n",
    "        \n",
    "    def forward(self, x, batch_size=128):\n",
    "        # Inputs --------------------------------------------------------------------\n",
    "        # x = list of three elements consisting of:\n",
    "        #   1. item context (longtensor of shape batch_size x (2*num_types))\n",
    "        #   2. previous linguistic message (longtensor of shape batch_size x len_message)\n",
    "        #   3. previous proposal (longtensor of shape batch_size x num_types)\n",
    "        # test = whether training or testing (testing selects actions greedily)\n",
    "        # batch_size = batch size\n",
    "        # Outputs -------------------------------------------------------------------\n",
    "        # term = binary variable where 1 indicates proposal accepted => game finished (longtensor of shape batch_size x 1)\n",
    "        # message = crafted linguistic message (longtensor of shape batch_size x len_message)\n",
    "        # prop = crafted proposal (longtensor of shape batch_size x num_types)\n",
    "        # entropy_loss = Number containing the sum of policy entropies (should be total entropy by additivity)\n",
    "        \n",
    "        # Update batch_size variable (changes throughout training due to sieving (see survivors below))\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Extract inputs ------------------------------------------------------------\n",
    "        \n",
    "        # Item context\n",
    "        x1 = x[0]\n",
    "        # Previous linguistic message\n",
    "        x2 = x[1]\n",
    "        # Previous proposal\n",
    "        x3 = x[2]  \n",
    "\n",
    "        # Encoding ------------------------------------------------------------------\n",
    "\n",
    "        # Initial embedding\n",
    "        x1 = self.encoder1(x1).transpose(0,1)\n",
    "        x2 = self.encoder2(x2).transpose(0,1)\n",
    "        x3 = self.encoder1(x3).transpose(0,1) # Same encoder as item context       \n",
    "            \n",
    "        # LSTM for item context\n",
    "        h1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c1 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h1 = h1.cuda()\n",
    "            c1 = c1.cuda()\n",
    "\n",
    "        for i in range(x1.size()[0]):\n",
    "            _, (h1,c1) = self.lstm1(x1[i].view(1,self.batch_size,self.embedding_dim),(h1,c1))\n",
    "        x1_encoded = h1\n",
    "        \n",
    "        # LSTM for linguistic\n",
    "        h2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c2 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h2 = h2.cuda()\n",
    "            c2 = c2.cuda()\n",
    "\n",
    "        for i in range(x2.size()[0]):\n",
    "            _, (h2,c2) = self.lstm2(x2[i].view(1,self.batch_size,self.embedding_dim),(h2,c2))\n",
    "        x2_encoded = h2\n",
    "        \n",
    "        # LSTM for proposal\n",
    "        h3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial hidden\n",
    "        c3 = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            h3 = h3.cuda()\n",
    "            c3 = c3.cuda()\n",
    "\n",
    "        for i in range(x3.size()[0]):\n",
    "            _, (h3,c3) = self.lstm3(x3[i].view(1,self.batch_size,self.embedding_dim),(h3,c3))\n",
    "        x3_encoded = h3\n",
    "\n",
    "        # Concatenate side-by-side\n",
    "        h = torch.cat([x1_encoded,x2_encoded,x3_encoded],2).view(self.batch_size,-1)\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ff(h)\n",
    "        h = F.relu(h) # Hidden layer input for policy networks\n",
    "        \n",
    "        # Policy ------------------------------------------------------------------\n",
    "\n",
    "        # Termination -----------------------------------------------\n",
    "        p_term = F.sigmoid(self.policy_term(h)).float()\n",
    "        #print(p_term)\n",
    "\n",
    "        # Entropy\n",
    "        one_tensor = torch.ones(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            one_tensor = one_tensor.cuda()\n",
    "        entropy_term = -(p_term * (p_term+1e-8).log()) \n",
    "        # Sample\n",
    "        term = torch.bernoulli(p_term).long()\n",
    "            \n",
    "        # log p for REINFORCE\n",
    "        log_p_term = torch.zeros(self.batch_size,1)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_term = log_p_term.cuda()\n",
    "\n",
    "        log_p_term = ((term.float() * p_term) + ((one_tensor-term.float()) * (one_tensor-p_term))+1e-8).log()\n",
    "\n",
    "        # Linguistic construction ----------------------------------\n",
    "        h_ling = h.clone().view(1,self.batch_size,self.embedding_dim) # Initial hidden state\n",
    "        c_ling = torch.zeros(1,self.batch_size,self.embedding_dim) # Initial cell state\n",
    "        letter = torch.zeros(self.batch_size,1).long() # Initial letter (dummy)\n",
    "        entropy_letter = torch.zeros([self.batch_size,len_message])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            c_ling = c_ling.cuda()\n",
    "            letter = letter.cuda()\n",
    "            entropy_letter = entropy_letter.cuda()\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_letter = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_letter = log_p_letter.cuda()\n",
    "\n",
    "        message = torch.zeros(self.batch_size,len_message) # Message\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            message = message.cuda()\n",
    "        for i in range(len_message):\n",
    "            embedded_letter = self.encoder2(letter)\n",
    "\n",
    "            _, (h_ling,c_ling) = self.policy_ling(embedded_letter.view(1,self.batch_size,self.embedding_dim),(h_ling,c_ling))\n",
    "            logit = self.ff_ling(h_ling.view(self.batch_size,self.embedding_dim))\n",
    "            p_letter = F.softmax(logit,dim=1).float()\n",
    "\n",
    "            entropy_letter[:,i] = -torch.sum(p_letter*(p_letter+1e-8).log(),1)\n",
    "            letter = torch.multinomial(p_letter,1).long()\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_letter, 1, letter)\n",
    "            log_p_letter = log_p_letter + (probs+1e-8).log()\n",
    "                \n",
    "            message[:,i] = letter.squeeze()\n",
    "            \n",
    "        message = message.long()\n",
    "        entropy_letter = torch.sum(entropy_letter,1,keepdim=True)\n",
    "   \n",
    "        # Proposal ----------------------------------------------\n",
    "        p_prop = []\n",
    "        prop = []\n",
    "        \n",
    "        #prop = torch.zeros([self.batch_size,num_types]).long()\n",
    "        entropy_prop_list = [0,0,0]\n",
    "        \n",
    "        # log p for REINFORCE \n",
    "        log_p_prop = torch.zeros([self.batch_size,1])\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            log_p_prop = log_p_prop.cuda()\n",
    "\n",
    "        for i in range(num_types):\n",
    "            p_prop.append(F.softmax(self.policy_prop[i](h),dim=1))\n",
    "            \n",
    "            entropy_prop_list[i] = -torch.sum(p_prop[i]*(p_prop[i]+1e-8).log(),1,keepdim=True)\n",
    "            \n",
    "            p_prop[i] = p_prop[i].view(self.batch_size,max_item+1)\n",
    "            \n",
    "            # Sample\n",
    "            #prop[:,i] = torch.multinomial(p_prop,1)\n",
    "            prop.append(torch.multinomial(p_prop[i],1))\n",
    "                \n",
    "            # Gather the probabilities for the letters we've picked\n",
    "            probs = torch.gather(p_prop[i], 1, prop[i].view(self.batch_size,1))\n",
    "            log_p_prop = log_p_prop + (probs+1e-8).log()\n",
    "              \n",
    "        prop = torch.stack(prop).transpose(0,1)\n",
    "        entropy_prop = torch.sum(torch.cat(entropy_prop_list,1),1,keepdim=True)\n",
    "\n",
    "        # Combine -----------------------------------------------------------------\n",
    "        entropy_loss = -(lambda1*entropy_term + lambda3*entropy_prop + lambda2*entropy_letter)\n",
    "        \n",
    "        #print(entropy_loss.size())\n",
    "        entropy_loss = entropy_loss.sum()\n",
    "        self.log_p = self.log_p + log_p_term + log_p_letter + log_p_prop\n",
    "        \n",
    "\n",
    "        return (term,message,prop, entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = combined_policy()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[128,6]).long()\n",
    "y = torch.randint(0,num_vocab,[128,6]).long()\n",
    "z = torch.randint(0,max_item,[128,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "blah = net([x,y,z])\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "for i in range(num_agents):\n",
    "    Agents.append(combined_policy())\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        Agents[i] = Agents[i].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ----------------\n",
      "Runtime for episodes 0-10: 0.879011869430542s\n",
      "Runtime for episodes 10-20: 0.5041623115539551s\n",
      "Runtime for episodes 20-30: 0.5302882194519043s\n",
      "Runtime for episodes 30-40: 0.5129055976867676s\n",
      "Runtime for episodes 40-50: 0.5537683963775635s\n",
      "Runtime for episodes 50-60: 0.46259188652038574s\n",
      "Runtime for episodes 60-70: 0.5315642356872559s\n",
      "Runtime for episodes 70-80: 0.5064384937286377s\n",
      "Runtime for episodes 80-90: 0.49396419525146484s\n",
      "End ------------------\n",
      "Total runtime: 5.444640636444092s\n"
     ]
    }
   ],
   "source": [
    "baselines = [0 for _ in range(num_agents)] # Baselines for reward calculation\n",
    "\n",
    "# Initialize optimizers for learning\n",
    "optimizers = []\n",
    "for i in range(num_agents):\n",
    "    optimizers.append(optim.Adam(Agents[i].parameters()))\n",
    "    \n",
    "# Recording train reward (see end of episode)\n",
    "r_list = []\n",
    "for i in range(num_agents):\n",
    "    r_list.append([])\n",
    "\n",
    "print('Start ----------------')\n",
    "time_start = time.time()\n",
    "time_p1 = time.time()\n",
    "# Loop over episodes\n",
    "for i_ep in range(N_ep):\n",
    "    #print(i_ep, '-----------------------------------------------------')\n",
    "    # Setting up games -----------------------------------------------------------------------\n",
    "    \n",
    "    # Game setup\n",
    "    \n",
    "    # Truncated Poisson sampling for number of turns in each game\n",
    "    N = truncated_poisson_sampling(lam, min_N, max_N, num_games)\n",
    "    \n",
    "    # Item pools for each game\n",
    "    pool = create_item_pool(num_types, max_item, num_games)\n",
    "    \n",
    "    # Item contexts for each game\n",
    "    item_contexts = [] # Each agent has different utilities (but same pool)\n",
    "    for i in range(num_agents):\n",
    "        utility = create_agent_utility(num_types, max_utility, num_games)\n",
    "        item_contexts.append(torch.cat([pool, utility],1))\n",
    "        \n",
    "    # For getting rid of finished games\n",
    "    survivors = torch.ones(num_games).nonzero()               # Keeps track of ongoing games; everyone alive initially\n",
    "    num_alive = len(survivors)                                # Actual batch size for each turn (initially num_games)\n",
    "    \n",
    "    # Initial inputs to the network\n",
    "    prev_messages = torch.zeros(num_games, len_message).long() # Previous linguistic message for each game\n",
    "    prev_proposals = torch.zeros(num_games, num_types).long()  # Previous proposal for each game\n",
    "\n",
    "    # For keeping track of sum of all rewards in the episode (used to calculate mean)\n",
    "    reward_sums = torch.zeros(2)\n",
    "    \n",
    "    # Initialize loss\n",
    "    losses = []\n",
    "    for j in range(num_agents):\n",
    "        losses.append(torch.zeros([],requires_grad=True))\n",
    "    \n",
    "    # Initialize log_p for REINFORCE\n",
    "    for j in range(num_agents):\n",
    "        Agents[j].log_p = torch.zeros([num_alive,1], requires_grad = True)\n",
    "\n",
    "    # cuda stuff\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        N = N.cuda()\n",
    "        pool = pool.cuda()\n",
    "        \n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j].cuda()\n",
    "            Agents[j].log_p = Agents[j].log_p.cuda()\n",
    "            losses[j] = losses[j].cuda()\n",
    "        \n",
    "        survivors = survivors.cuda()\n",
    "        prev_messages = prev_messages.cuda()\n",
    "        prev_proposals = prev_proposals.cuda()\n",
    "        \n",
    "        reward_sums = reward_sums.cuda()\n",
    "\n",
    "    # Play the games -------------------------------------------------------------------------\n",
    "    for i_turn in range(max_N): # Loop through maximum possible number of turns for all games\n",
    "        \n",
    "        reward_losses = []\n",
    "        entropy_losses = []\n",
    "        for j in range(num_agents):\n",
    "            # Losses for each agent\n",
    "            reward_losses.append(torch.zeros([],requires_grad=True))\n",
    "            entropy_losses.append(torch.zeros([],requires_grad=True))\n",
    "            \n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                reward_losses[j] = reward_losses[j].cuda()\n",
    "                entropy_losses[j] = entropy_losses[j].cuda()\n",
    "                \n",
    "        \n",
    "        # Agent IDs\n",
    "        id_1 = i_turn % 2    # Current player\n",
    "        id_2 = int(not id_1) # Other player\n",
    "        \n",
    "        # Remove finished games (batch size decreases)\n",
    "        N = N[survivors].view(num_alive, 1)\n",
    "        pool = pool[survivors].view(num_alive, num_types)\n",
    "        prev_messages = prev_messages[survivors].view(num_alive, len_message)\n",
    "        prev_proposals = prev_proposals[survivors].view(num_alive, num_types)\n",
    "        if torch.cuda.is_available() and use_cuda: # Necessary?\n",
    "            N = N.cuda()\n",
    "            pool = pool.cuda()\n",
    "            prev_messages = prev_messages.cuda()\n",
    "            prev_proposals = prev_proposals.cuda()\n",
    "        for j in range(num_agents):\n",
    "            item_contexts[j] = item_contexts[j][survivors].view(num_alive,num_types*2)\n",
    "            Agents[j].log_p = Agents[j].log_p[survivors].view(num_alive,1)\n",
    "            if torch.cuda.is_available() and use_cuda:\n",
    "                item_contexts[j] = item_contexts[j].cuda() # Necessaire?\n",
    "        \n",
    "        # Agent currently playing\n",
    "        Agent = Agents[id_1]             \n",
    "        item_context = item_contexts[id_1]\n",
    "        \n",
    "        # Play the game -------------------------------------------------------------\n",
    "        term, prev_messages, proposals, entropy_loss = Agent([item_context, prev_messages, prev_proposals], num_alive)\n",
    "        entropy_losses[id_1] = entropy_loss\n",
    "        \n",
    "        # Compute reward loss (assumes 2 agents) ------------------------------------\n",
    "        \n",
    "        # Games terminated by the current agent (previous proposal accepted)\n",
    "        finishers = term.squeeze().nonzero()          # squeeze is for getting rid of extra useless dimension that pops up for some reason\n",
    "        num_finishers = len(finishers)\n",
    "\n",
    "        # On the first turn there is no prev. proposal so terminating gives zero reward\n",
    "        if num_finishers != 0 and i_turn != 0:\n",
    "            pool_12 = pool[finishers].view(num_finishers,num_types)\n",
    "            \n",
    "            share_2 = prev_proposals[finishers].view(num_finishers,num_types) # Share of other (previous proposal) \n",
    "            share_1 = pool_12 - share_2 # Share of this agent (remainder)\n",
    "            \n",
    "            # Zero reward if proposal exceeds pool\n",
    "            invalid_batches = torch.sum(share_2>pool_12,1)>0\n",
    "            share_2[invalid_batches] = 0\n",
    "            share_1[invalid_batches] = 0\n",
    "            \n",
    "            utility_1 = item_contexts[id_1][:,num_types:] # Recall that item context is a concatenation of pool and utility\n",
    "            utility_1 = utility_1[finishers].view(num_finishers,num_types)\n",
    "            utility_2 = item_contexts[id_2][:,num_types:]\n",
    "            utility_2 = utility_2[finishers].view(num_finishers,num_types)\n",
    "\n",
    "            log_p_1 = Agents[id_1].log_p[finishers].view(num_finishers,1)\n",
    "            log_p_2 = Agents[id_2].log_p[finishers].view(num_finishers,1)\n",
    "\n",
    "            # Calculate reward and reward losses\n",
    "            r1, rl1 = rewards_func(share_1, utility_1, pool_12, log_p_1, baselines[id_1])\n",
    "            r2, rl2 = rewards_func(share_2, utility_2, pool_12, log_p_2, baselines[id_2])\n",
    "            \n",
    "            # Add rewards and reward losses\n",
    "            reward_losses[id_1] = rl1\n",
    "            reward_losses[id_2] = rl2\n",
    "\n",
    "            # Summing over all finished games\n",
    "            reward_sums[id_1] = reward_sums[id_1] + r1.sum()\n",
    "            reward_sums[id_2] = reward_sums[id_2] + r2.sum()\n",
    "            \n",
    "            # Accumulate entropy loss\n",
    "            #losses[id_1] = losses[id_1] + entropy_losses[id_1]\n",
    "            #losses[id_2] = losses[id_2] + entropy_losses[id_2]\n",
    "            \n",
    "            # Accumulate reward loss\n",
    "            #losses[id_1] += rl1\n",
    "            #losses[id_2] += rl2\n",
    "            \n",
    "        \n",
    "\n",
    "        prev_proposals = proposals # Don't need previous proposals anymore so update it\n",
    "        \n",
    "        \n",
    "        # Wrapping up the end of turn ------------------------------------------------\n",
    "        # Remove finished games\n",
    "        # In term and term_N, element = 1 means die\n",
    "        term_N = (N <= (i_turn+1)).view(num_alive,1).long() # Last turn reached; i_turn + 1 since i_turn starts counting from 0\n",
    "        # In survivors, element = 1 means live\n",
    "        survivors = (term+term_N) == 0\n",
    "\n",
    "        # Check if everyone's dead\n",
    "        if survivors.sum() == 0: # If all games over, break episode\n",
    "            break;\n",
    "            \n",
    "        # Reshape\n",
    "        survivors = ((term+term_N) == 0).nonzero()[:,0].view(-1,1)\n",
    "        num_alive = len(survivors) # Number of survivors\n",
    "        \n",
    "    # End of episode\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(num_agents):\n",
    "        # optimize\n",
    "        optimizers[i].zero_grad()\n",
    "        losses[i].backward()\n",
    "        #print(Agents[i].policy_term.weight.grad.sum())\n",
    "        optimizers[i].step()\n",
    "    \n",
    "    for j in range(num_agents):\n",
    "        r_mean = reward_sums[j]/num_games # Overall episode batch-averaged reward\n",
    "        \n",
    "        # Update baseline with batch-averaged reward\n",
    "        baselines[j] = smoothing_const * baselines[j] + (1-smoothing_const)*r_mean\n",
    "        \n",
    "        # Record batch-averaged reward\n",
    "        if (i_ep % ep_record == 0):\n",
    "            r_list[j].append(r_mean)\n",
    "\n",
    "    # Record partial runtime\n",
    "    if (i_ep % ep_time == 0) and (i_ep != 0):\n",
    "        time_p2 = time.time()\n",
    "        print('Runtime for episodes ' + str(i_ep-ep_time) + '-' + str(i_ep) + ': ' + str(time_p2 - time_p1) + 's')\n",
    "        time_p1 = time_p2\n",
    "\n",
    "print('End ------------------')\n",
    "time_finish = time.time()\n",
    "print('Total runtime: ' + str(time_finish-time_start) + 's')\n",
    "\n",
    "# Save trained models\n",
    "\n",
    "#for i in range(num_agents):\n",
    "#    torch.save(Agents[0].state_dict(),'saved_model_agent_' + str(i) + '.pt')\n",
    "    \n",
    "# Template for loading\n",
    "\n",
    "#Agents[0].load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Agents[0].ff.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(Agents[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f262b1470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(r_list[0]))*ep_record\n",
    "plt.plot(epoch_list,r_list[0], label='Agent 1')\n",
    "plt.plot(epoch_list,r_list[1], label='Agent 2')\n",
    "plt.ylabel('Average reward in epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim([0,ep_record*len(r_list[0])])\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "if save_plot:\n",
    "    plt.savefig('N_ep='+str(N_ep)+'_seed='+str(num_seed)+'_sum_refreg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy inputs\n",
    "x = torch.randint(0,max_item,[1,6]).long()\n",
    "y = torch.randint(0,num_vocab,[1,6]).long()\n",
    "z = torch.randint(0,max_item,[1,3]).long()\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
